{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "from slicing_inference import sahi_slicing_inference\n",
    "from inference_modular import ship_detection\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "from imageutils import resize_img\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\debug_images\\2.jpg\"\n",
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\inference_images\\dd4ffcb5c.jpg\"\n",
    "images_path = r\"D:\\NLP 1\\Sat_object_detection\\inference_images\"\n",
    "images_path = r\"D:\\NLP 1\\Sat_object_detection\\debug_images_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP 1\\venv\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "D:\\NLP 1\\venv\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model takes a while to load for the first inference.\n",
      "Processing 011409565.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 032610514.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 058358044.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 058358044.jpg\n",
      "Processing 1.jpg\n",
      "Performing prediction on 12 number of slices.\n",
      "15 bboxes found in 1.jpg\n",
      "Processing 12572286c.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 14013864b.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 18609713e.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 18609713e.jpg\n",
      "Processing 1_2.jpg\n",
      "Performing prediction on 9 number of slices.\n",
      "12 bboxes found in 1_2.jpg\n",
      "Processing 1_3.jpg\n",
      "Performing prediction on 9 number of slices.\n",
      "14 bboxes found in 1_3.jpg\n",
      "Processing 26095039a.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 26823809a.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 26823809a.jpg\n",
      "Processing 2d1b074cb.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "6 bboxes found in 2d1b074cb.jpg\n",
      "Processing 2_1.jpg\n",
      "Performing prediction on 36 number of slices.\n",
      "13 bboxes found in 2_1.jpg\n",
      "Processing 2_2.jpg\n",
      "Performing prediction on 25 number of slices.\n",
      "16 bboxes found in 2_2.jpg\n",
      "Processing 38168248b.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 38168248b.jpg\n",
      "Processing 38988163c.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 38988163c.jpg\n",
      "Processing 5.jpg\n",
      "Performing prediction on 8 number of slices.\n",
      "14 bboxes found in 5.jpg\n",
      "Processing 55236555e.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 6.png\n",
      "Performing prediction on 6 number of slices.\n",
      "5 bboxes found in 6.png\n",
      "Processing 7242578f3.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 7242578f3.jpg\n",
      "Processing 7272882ed.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 7937980e1.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 7937980e1.jpg\n",
      "Processing 8166432c8.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 8166432c8.jpg\n",
      "Processing 8316753c8.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "5 bboxes found in 8316753c8.jpg\n",
      "Processing 8591865ee.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 91297604d.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing b10854744.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing b1169302a.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b1169302a.jpg\n",
      "Processing b172ed972.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b172ed972.jpg\n",
      "Processing b1871209d.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "2 bboxes found in b1871209d.jpg\n",
      "Processing b1bb86b1b.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b1bb86b1b.jpg\n",
      "Processing b1c675f70.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b1c675f70.jpg\n",
      "Processing b298cfd77.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "3 bboxes found in b298cfd77.jpg\n",
      "Processing b2cca1dd3.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b2cca1dd3.jpg\n",
      "Processing b2eb59683.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "5 bboxes found in b2eb59683.jpg\n",
      "Processing b36ad6b4d.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b36ad6b4d.jpg\n",
      "Processing b399eb51e.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b399eb51e.jpg\n",
      "Processing b3e786c01.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "4 bboxes found in b3e786c01.jpg\n",
      "Processing b3f7b5124.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "4 bboxes found in b3f7b5124.jpg\n",
      "Processing b4b3caa34.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b4b3caa34.jpg\n",
      "Processing b4e599398.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b4e599398.jpg\n",
      "Processing b6c0a7d84.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b6c0a7d84.jpg\n",
      "Processing b7318c374.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b7318c374.jpg\n",
      "Processing b7f57d9e8.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing b7f69ade4.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b7f69ade4.jpg\n",
      "Processing b854d6051.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing b879be66a.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing b94f7a644.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "4 bboxes found in b94f7a644.jpg\n",
      "Processing b95d6dd9c.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing b99aac0ce.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "3 bboxes found in b99aac0ce.jpg\n",
      "Processing b9b9bdc26.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in b9b9bdc26.jpg\n",
      "Processing b9c417685.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing bb31234d9.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing bb976cabb.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "2 bboxes found in bb976cabb.jpg\n",
      "Processing bba0d8ed5.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in bba0d8ed5.jpg\n",
      "Processing d40740a01.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in d40740a01.jpg\n",
      "Processing d4837d743.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in d4837d743.jpg\n",
      "Processing da3c51637.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in da3c51637.jpg\n",
      "Processing da3ee2f80.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "2 bboxes found in da3ee2f80.jpg\n",
      "Processing dad047800.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in dad047800.jpg\n",
      "Processing db8c4b728.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in db8c4b728.jpg\n",
      "Processing dbbe8bc63.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in dbbe8bc63.jpg\n",
      "Processing dc007abd3.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in dc007abd3.jpg\n",
      "Processing dc0f2e22b.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in dc0f2e22b.jpg\n",
      "Processing dd4ffcb5c.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "3 bboxes found in dd4ffcb5c.jpg\n",
      "Processing df648f2f4.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in df648f2f4.jpg\n",
      "Processing dfdfc012a.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in dfdfc012a.jpg\n",
      "Processing dfe1d30a7.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in dfe1d30a7.jpg\n",
      "Processing dff7a31fc.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in dff7a31fc.jpg\n",
      "Processing e0b6f0185.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "5 bboxes found in e0b6f0185.jpg\n",
      "Processing e3adcb329.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in e3adcb329.jpg\n",
      "Processing e3da55562.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in e3da55562.jpg\n",
      "Processing e7dfaf709.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in e7dfaf709.jpg\n",
      "Processing e7e24507a.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "8 bboxes found in e7e24507a.jpg\n",
      "Processing e7e2c2aa6.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in e7e2c2aa6.jpg\n"
     ]
    }
   ],
   "source": [
    "from inference_modular import ship_detection\n",
    "\n",
    "# images_dir = r\"D:\\NLP 1\\Sat_object_detection\\Test_images\\debug_images_2\"\n",
    "images_dir = r\"D:\\NLP 1\\Sat_object_detection\\Test_images\\debug_images_3\"\n",
    "# images_dir = r\"D:\\NLP 1\\Sat_object_detection\\Test_images\\inference_images\"\n",
    "# images_dir = r\"D:\\NLP 1\\Sat_object_detection\\Test_images\\ship\"\n",
    "\n",
    "coord = {\"0c0d90d8d.jpg\": [58.4893887115, 23.6396684794, 58.4961460224, 23.6487324542],\n",
    "         \"2d1b074cb.jpg\": [47.3562147890, 26.3220918742, 47.3646843251, 26.3311658917],}\n",
    "\n",
    "result = ship_detection(images=images_dir, bbox_coord_wgs84=coord, annotations=[\"length\", \"coord\"], nms_iou_threshold=0.15, scale_down_factor= \"adaptive\",\n",
    "                        adaptive_scale_down_parameters = {'a': 0.2, 'b': 0.5, 'threshold': 3}, model_input_dim=768, confidence_threshold=0.7, sahi_overlap_ratio=0.33,\n",
    "                        output_annotated_image=True, save_annotated_image=True, annotation_font_size=15, annotation_font=r\"calibri.ttf\", annotation_bbox_width=1, \n",
    "                        output_original_image=True, output_dir=None, output_name=\"prediction\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"2d1b074cb.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result[\"2d1b074cb.jpg\"][\"original_image\"]\n",
    "result[\"2d1b074cb.jpg\"][\"annotated_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageutils import draw_bbox_torchvision\n",
    "\n",
    "image = result[\"2d1b074cb.jpg\"]\n",
    "annotated_image = draw_bbox_torchvision(image=image[\"original_image\"], bboxes=image[\"bboxes\"], scores=image[\"scores\"], lengths=image[\"ships_lengths\"], \n",
    "                        ships_coords=image[\"ships_long_lat\"], annotations=[\"score\", \"length\", \"coord\"], save=False, image_save_name=r\"C:\\Users\\user2\\Desktop\\b.jpg\",\n",
    "                        output_annotated_image=True, font_size=20, font=r\"calibri.ttf\", bbox_width=1)\n",
    "annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"2d1b074cb.jpg\"][\"ships_long_lat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"dad047800.jpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images dictionary mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "images_paths = [r\"D:\\NLP 1\\Sat_object_detection\\inference_images\\dd4ffcb5c.jpg\",\n",
    "                r\"D:\\NLP 1\\Sat_object_detection\\debug_images_2\\2_2.jpg\",\n",
    "                r\"D:\\NLP 1\\Sat_object_detection\\debug_images_2\\e0b6f0185.jpg\"\n",
    "                ]\n",
    "coords = [[58.4893887115, 23.6396684794, 58.4961460224, 23.6487324542], \n",
    "          [47.3562147890, 26.3220918742, 47.3646843251, 26.3311658917],\n",
    "          [62.5293887115, 18.9696684794, 62.5361460224, 18.9787324542],]\n",
    "images_dict = {}\n",
    "coords_dict = {}\n",
    "for idx, img_path in enumerate(images_paths):\n",
    "    img_name = \"image{0:03}\".format(idx+1)\n",
    "    images_dict[img_name] = {}\n",
    "    images_dict[img_name]['image'] = Image.open(img_path)\n",
    "\n",
    "    coords_dict[img_name] = coords[idx]\n",
    "\n",
    "print(images_dict)\n",
    "print(coords_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_modular import ship_detection\n",
    "result = ship_detection(images=images_dict, bbox_coord_wgs84=coords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['image001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['image001']['ships_bbox_dimensions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single image mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "\n",
      "The model takes a while to load for the first inference.\n",
      "Processing prediction\n",
      "Performing prediction on 9 number of slices.\n",
      "12 bboxes found in prediction\n"
     ]
    }
   ],
   "source": [
    "from inference_modular import ship_detection\n",
    "from PIL import Image\n",
    "# images_path = r\"D:\\NLP 1\\Sat_object_detection\\inference_images\"\n",
    "# images_path = r\"D:\\NLP 1\\Sat_object_detection\\debug_images_2\\e7e24507a.jpg\"\n",
    "# images_path = r\"D:\\NLP 1\\Sat_object_detection\\Test_images\\debug_images_3\\2_2.jpg\"\n",
    "images_path = r\"D:\\NLP 1\\Sat_object_detection\\sentinel-concat\\2023-07-05_2023-09-25-[58.7, 23.6, 58.9, 23.8]-res5-(2500, 2500)-mostRecent-sentinel-2-l1c-maxcc0.8.jpg\"\n",
    "img = Image.open(images_path)\n",
    "print(type(img))\n",
    "coord = [58.4893887115,23.6396684794,58.4961460224,23.6487324542]\n",
    "bbox_coords = [58.7, 23.6, 58.9, 23.8]\n",
    "\n",
    "result = ship_detection(images=img, bbox_coord_wgs84=bbox_coords, annotations=[\"length\", \"coord\"], nms_iou_threshold=0.15,scale_down_factor= \"adaptive\",\n",
    "                        adaptive_scale_down_parameters = {'a': 0.3, 'b': 1, 'threshold': 1.5}, confidence_threshold=0.9, sahi_overlap_ratio=0.33,\n",
    "                        output_annotated_image=True, save_annotated_image=False, output_original_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_obj': 12,\n",
       " 'bboxes': array([[ 870.2271 , 1200.6638 ,  907.55164, 1242.7515 ],\n",
       "        [ 307.841  ,  724.79175,  369.17755,  947.27185],\n",
       "        [ 571.80225, 1284.5826 ,  743.38477, 1463.3835 ],\n",
       "        [ 721.8714 ,  601.0584 ,  738.96906,  653.2425 ],\n",
       "        [ 728.7779 , 1022.656  ,  769.42334, 1071.8563 ],\n",
       "        [1462.383  ,  551.0234 , 1485.6593 ,  631.4449 ],\n",
       "        [ 732.8922 ,  537.0385 ,  784.9386 ,  556.9904 ],\n",
       "        [1414.4629 ,  558.73627, 1429.0151 ,  602.21216],\n",
       "        [1428.4951 ,  642.0514 , 1445.8538 ,  710.02576],\n",
       "        [1430.1279 ,  549.92633, 1443.0115 ,  605.79504],\n",
       "        [1371.1829 ,  543.43524, 1419.4663 ,  560.76465],\n",
       "        [1435.1926 ,  611.4829 , 1443.9192 ,  642.8814 ]], dtype=float32),\n",
       " 'scores': array([0.99852556, 0.99786985, 0.9977182 , 0.9966708 , 0.9935874 ,\n",
       "        0.99181503, 0.9881153 , 0.98557925, 0.983603  , 0.98101085,\n",
       "        0.9630907 , 0.9152051 ], dtype=float32),\n",
       " 'original_image': <PIL.Image.Image image mode=RGB size=1653x1653>,\n",
       " 'ships_long_lat': [(58.807548627259, 23.747817016528),\n",
       "  (58.740956960356, 23.701153272755),\n",
       "  (58.779563642572, 23.766241155995),\n",
       "  (58.788375103091, 23.675880272433),\n",
       "  (58.790635279605, 23.726709752391),\n",
       "  (58.878344977645, 23.67153468008),\n",
       "  (58.791822795556, 23.666184448316),\n",
       "  (58.872019239404, 23.67023281829),\n",
       "  (58.873886804413, 23.681795350783),\n",
       "  (58.873813636074, 23.669916602271),\n",
       "  (58.868823301266, 23.666799755062),\n",
       "  (58.874174943521, 23.675884105131)],\n",
       " 'ships_lengths': [729.6,\n",
       "  2993.2,\n",
       "  3203.3,\n",
       "  702.1,\n",
       "  830.2,\n",
       "  1082.0,\n",
       "  695.6,\n",
       "  584.9,\n",
       "  914.5,\n",
       "  751.6,\n",
       "  639.3,\n",
       "  422.4],\n",
       " 'ships_bbox_dimensions': [(566.2, 460.2),\n",
       "  (2993.2, 756.2),\n",
       "  (2405.5, 2115.4),\n",
       "  (702.1, 210.8),\n",
       "  (661.9, 501.1),\n",
       "  (1082.0, 287.0),\n",
       "  (641.7, 268.4),\n",
       "  (584.9, 179.4),\n",
       "  (914.5, 214.0),\n",
       "  (751.6, 158.8),\n",
       "  (595.3, 233.1),\n",
       "  (422.4, 107.6)],\n",
       " 'annotated_image': <PIL.Image.Image image mode=RGB size=1653x1653>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"annotated_image\"]\n",
    "# result[\"original_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageutils import draw_bbox_torchvision\n",
    "\n",
    "image = result\n",
    "annotated_image = draw_bbox_torchvision(image=image[\"original_image\"], bboxes=image[\"bboxes\"], scores=image[\"scores\"], lengths=image[\"ships_lengths\"], \n",
    "                        ships_coords=image[\"ships_long_lat\"], annotations=[\"score\", \"length\", \"coord\"], save=False, image_save_name=r\"C:\\Users\\user2\\Desktop\\b.jpg\",\n",
    "                        output_annotated_image=True, font_size=20, font=r\"calibri.ttf\", bbox_width=2)\n",
    "annotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use draw_bbox_torchvision separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageutils import draw_bbox_torchvision\n",
    "annotated_image = draw_bbox_torchvision(image=result[\"original_image\"], bboxes=result[\"bboxes\"], scores=result[\"scores\"], lengths=result[\"ships_length\"], \n",
    "                        ships_coords=result[\"ships_long_lat\"], annotations=[\"score\"], save=True, image_save_name=r\"C:\\Users\\user2\\Desktop\\b.jpg\", output_annotated_image=True)\n",
    "annotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_names = [\"Image{0:03}\".format(i) for i in range(100)]\n",
    "images = [i for i in range(100)]\n",
    "\n",
    "images_dict = {images_names[i]:{\"image\": images[i]} for i in range(len(images_names))}\n",
    "images_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "def func(x, a, b, c):\n",
    "    return (a * x**2 + b*x + c) # a and d are redundant\n",
    "\n",
    "dim_c =  [2   , 3   ,  4   , 5   , 6  , 7   ,  8  ,  9  , 10 , ]\n",
    "dim_c2 = [1.2 , 1.4 , 1.6  , 1.8 , 2  , 2.2 , 2.4 , 2.6 ,  3 , ]\n",
    "p , _ = curve_fit(func, dim_c, dim_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y = {p[0]:.2f}x**2 + {p[1]:.2f}*x + {p[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
