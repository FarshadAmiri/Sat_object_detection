{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slicing_inference import sahi_slicing_inference\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from imageutils import resize_img\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 8 number of slices.\n",
      "Object found -> bbox:  [290.67914 512.6692  333.07648 667.62524]\n",
      "Object found -> bbox:  [582.70105 424.4006  594.5731  459.0754 ]\n",
      "Object found -> bbox:  [589.0596  724.09076 616.5419  758.63434]\n",
      "Object found -> bbox:  [587.81854 379.13177 626.6871  393.10223]\n",
      "Object found -> bbox:  [490.6183  390.73325 506.50665 440.93832]\n",
      "Object found -> bbox:  [466.03265 451.71088 477.8919  499.84845]\n",
      "Object found -> bbox:  [425.17847 384.7847  457.38507 396.3138 ]\n",
      "Object found -> bbox:  [490.50882 446.50525 499.03775 469.39404]\n",
      "Object found -> bbox:  [456.107   395.19382 464.78827 424.93655]\n",
      "Object found -> bbox:  [410.62286 390.77545 426.52258 440.72778]\n",
      "Object found -> bbox:  [386.14456 450.70663 397.69846 499.03232]\n",
      "Object found -> bbox:  [345.39575 384.60666 377.41205 396.21536]\n",
      "Object found -> bbox:  [387.42926 388.20602 395.8802  427.38083]\n",
      "Object found -> bbox:  [410.3145  446.34796 419.13892 469.3927 ]\n",
      "Object found -> bbox:  [376.37534 394.4052  385.2734  425.19354]\n",
      "Object found -> bbox:  [478.2075  298.52667 599.36096 424.55682]\n",
      "Object found -> bbox:  [687.7169  238.36775 712.0918  266.36865]\n",
      "Object found -> bbox:  [588.86444 113.96368 615.4003  145.36212]\n",
      "Object found -> bbox:  [581.31934 305.29077 742.46436 423.4693 ]\n",
      "Object found -> bbox:  [ 72.74679 238.10062  96.91134 266.3729 ]\n",
      "Object found -> bbox:  [  0.930748 309.248    133.28104  423.86902 ]\n",
      "Object found -> bbox:  [9.7036362e-03 2.4559338e+02 1.7792309e+01 2.6626334e+02]\n"
     ]
    }
   ],
   "source": [
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\debug_images\\2.jpg\"\n",
    "result = sahi_slicing_inference(image_path, scale_factor=4, confidence_threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[(905.6791381835938, 512.669189453125, 948.0764770507812, 667.625244140625), (1093.2074890136719, 908.5266723632812, 1214.3609619140625, 1034.5568237304688), (1302.7169189453125, 848.1006164550781, 1327.792308807373, 876.3728942871094), (1720.6182861328125, 390.7332458496094, 1736.5225830078125, 440.9383239746094), (1197.7010498046875, 424.4006042480469, 1209.5731201171875, 459.0754089355469), (1696.0326538085938, 450.7066345214844, 1707.8919067382812, 499.84844970703125), (1196.3193359375, 915.290771484375, 1363.2810363769531, 1033.8690185546875), (1203.8644409179688, 723.9636764526367, 1231.5418701171875, 758.6343383789062), (1655.178466796875, 384.6066589355469, 1687.4120483398438, 396.3138122558594), (1720.3145141601562, 446.34796142578125, 1729.138916015625, 469.39404296875), (1202.8185424804688, 379.13177490234375, 1241.6870727539062, 393.10223388671875), (1697.4292602539062, 388.2060241699219, 1705.8801879882812, 427.3808288574219), (1686.1069946289062, 394.40521240234375, 1695.2734069824219, 425.19354248046875)]\n",
      "[0.9990602135658264, 0.9972919821739197, 0.992735743522644, 0.9923374056816101, 0.9837902188301086, 0.975692629814148, 0.9681785702705383, 0.9670384526252747, 0.965222954750061, 0.9551853537559509, 0.9417101144790649, 0.9336445927619934, 0.9266908764839172]\n",
      "(2078, 1378)\n"
     ]
    }
   ],
   "source": [
    "print(result['n_obj'])\n",
    "print(result['bboxes'])\n",
    "print(result['scores'])\n",
    "print(result[\"resized_image_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['prediction'].export_visuals(export_dir=\"demo_data/\", hide_labels=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "p = 110\n",
    "round(math.sqrt(p / 25), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8313, 5513)\n",
      "(8313, 5513)\n",
      "5513\n",
      "8313\n"
     ]
    }
   ],
   "source": [
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\debug_images\\2.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "print(image.size)\n",
    "image = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "print(image.size)\n",
    "w, h = image.size\n",
    "print(h)\n",
    "print(w)\n",
    "# Init output image.\n",
    "# image_out = np.empty((n_rows, n_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5513\n",
      "8313\n"
     ]
    }
   ],
   "source": [
    "image = np.asarray(Image.open(image_path))\n",
    "h, w, _ = image.shape\n",
    "print(h)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAHI_ACTIVATION_THRESHOLD = 4\n",
    "IMG_DIM = 768\n",
    "SAHI_ADAPTIVE_RESIZING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8313\n",
      "5513\n",
      "SAHI_SCALE_DOWN_FACTOR : 1.8\n"
     ]
    }
   ],
   "source": [
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\debug_images\\2.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\\\n",
    "\n",
    "w, h = image.size\n",
    "print(w)\n",
    "print(h)\n",
    "\n",
    "if w * h > SAHI_ACTIVATION_THRESHOLD * IMG_DIM * IMG_DIM:\n",
    "    if SAHI_ADAPTIVE_RESIZING == True:\n",
    "        p = (w * h) // (IMG_DIM * IMG_DIM)\n",
    "        if p > 6:\n",
    "            SAHI_SCALE_DOWN_FACTOR = round(math.sqrt(p / 25), 1)\n",
    "        else:\n",
    "            SAHI_SCALE_DOWN_FACTOR = 1\n",
    "\n",
    "print(f\"SAHI_SCALE_DOWN_FACTOR : {SAHI_SCALE_DOWN_FACTOR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3062\n",
      "4618\n"
     ]
    }
   ],
   "source": [
    "h_r = h//SAHI_SCALE_DOWN_FACTOR\n",
    "w_r = w//SAHI_SCALE_DOWN_FACTOR\n",
    "\n",
    "h_r, w_r = map(int, (h_r, w_r))\n",
    "print(h_r)\n",
    "print(w_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "resized_image = resize_img(image= image, height= h_r, width=w_r)\n",
    "resized_image = Image.fromarray(np.uint8(resized_image)).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0855, 0.8550, 0.0855, 0.0855, 0.8550, 0.0855])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.Tensor([0.0855, 0.855, 0.0855, 0.0855, 0.855, 0.0855])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False,  True, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptable_scores_mask = np.array([i > 0.8 for i in scores])\n",
    "acceptable_scores_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6])\n",
    "a = a[acceptable_scores_mask]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
