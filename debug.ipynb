{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "from slicing_inference import sahi_slicing_inference\n",
    "from inference_modular import ship_detection\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "from imageutils import resize_img\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\debug_images\\2.jpg\"\n",
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\inference_images\\dd4ffcb5c.jpg\"\n",
    "images_path = r\"D:\\NLP 1\\Sat_object_detection\\inference_images\"\n",
    "images_path = r\"D:\\NLP 1\\Sat_object_detection\\debug_images_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_down_rate: 1.4190985511071967\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1.323046875\n",
      "scale_down_rate: 3.394435149887947\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 2.57421875\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "scale_down_rate: 1\n",
      "Processing 1.jpg\n",
      "Performing prediction on 6 number of slices.\n",
      "12 bboxes found in 1.jpg\n",
      "Processing 12572286c.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 14013864b.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 1_2.jpg\n",
      "Performing prediction on 4 number of slices.\n",
      "9 bboxes found in 1_2.jpg\n",
      "Processing 2.jpg\n",
      "Performing prediction on 15 number of slices.\n",
      "13 bboxes found in 2.jpg\n",
      "Processing 26095039a.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 26823809a.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 26823809a.jpg\n",
      "Processing 2d1b074cb.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "5 bboxes found in 2d1b074cb.jpg\n",
      "Processing 2_2.jpg\n",
      "Performing prediction on 9 number of slices.\n",
      "13 bboxes found in 2_2.jpg\n",
      "Processing 38168248b.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 38168248b.jpg\n",
      "Processing 38988163c.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 38988163c.jpg\n",
      "Processing 55236555e.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 7242578f3.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 7242578f3.jpg\n",
      "Processing 7272882ed.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing 7937980e1.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in 7937980e1.jpg\n",
      "Processing 8591865ee.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "Processing da3ee2f80.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in da3ee2f80.jpg\n",
      "Processing dd4ffcb5c.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "3 bboxes found in dd4ffcb5c.jpg\n",
      "Processing df648f2f4.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "1 bboxes found in df648f2f4.jpg\n",
      "Processing e7e24507a.jpg\n",
      "Performing prediction on 1 number of slices.\n",
      "7 bboxes found in e7e24507a.jpg\n"
     ]
    }
   ],
   "source": [
    "from inference_modular import ship_detection\n",
    "\n",
    "# images_dir = r\"D:\\NLP 1\\Sat_object_detection\\debug_images_2\"\n",
    "images_dir = r\"D:\\NLP 1\\Sat_object_detection\\debug_images_3\"\n",
    "# images_dir = r\"D:\\NLP 1\\Sat_object_detection\\inference_images\"\n",
    "\n",
    "coord = {\"0c0d90d8d.jpg\": [58.4893887115, 23.6396684794, 58.4961460224, 23.6487324542],\n",
    "         \"2d1b074cb.jpg\": [47.3562147890, 26.3220918742, 47.3646843251, 26.3311658917],}\n",
    "\n",
    "result = ship_detection(images=images_dir, bbox_coord_wgs84=coord, annotations=[\"score\", \"length\", \"coord\"], nms_iou_threshold=0.2, scale_down_factor= \"adaptive\",\n",
    "                        adaptive_scale_down_parameters = {'a': 0.3, 'b': 0.5, 'threshold': 1.5}, model_input_dim=768, confidence_threshold=0.85, sahi_overlap_ratio=0.3,\n",
    "                        output_annotated_image=True, save_annotated_image=True, annotation_font_size=17, annotation_bbox_width=3, output_original_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"9196798a9.jpg\"][\"original_image\"]\n",
    "result[\"9196798a9.jpg\"][\"annotated_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_obj': 4,\n",
       " 'bboxes': array([[593.7077 ,  45.92871, 753.17255, 254.45227],\n",
       "        [620.5995 , 627.19763, 637.94653, 635.86365],\n",
       "        [180.73062, 636.78705, 194.8421 , 644.33075],\n",
       "        [119.95   , 644.51044, 133.83653, 653.96564]], dtype=float32),\n",
       " 'scores': array([0.9998567 , 0.9744727 , 0.9333982 , 0.88371474], dtype=float32),\n",
       " 'original_image': <PIL.Image.Image image mode=RGB size=768x768>,\n",
       " 'ships_long_lat': [(58.495314029591, 23.641441035159),\n",
       "  (58.494925421619, 23.647121835915),\n",
       "  (58.491040965183, 23.647228387887),\n",
       "  (58.490505192283, 23.647330819514)],\n",
       " 'ships_lengths': [308.8, 19.2, 16.0, 17.5],\n",
       " 'ships_bbox_dimensions': [(273.7, 142.9),\n",
       "  (15.5, 11.4),\n",
       "  (12.6, 9.9),\n",
       "  (12.4, 12.4)],\n",
       " 'annotated_image': <PIL.Image.Image image mode=RGB size=768x768>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"0c0d90d8d.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"0c0d90d8d.jpg\"][\"annotated_image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images dictionary mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single image mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP 1\\venv\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "D:\\NLP 1\\venv\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "Processing prediction\n",
      "Performing prediction on 40 number of slices.\n",
      "15 bboxes found in prediction\n",
      "<class 'PIL.Image.Image'>\n",
      "[[2603.2327  1696.1818  2656.5952  1754.404  ]\n",
      " [2404.616   1446.2915  2461.3486  1511.8029 ]\n",
      " [2393.7095   847.49524 2418.5342   921.32385]\n",
      " [1809.9097  1024.9023  1896.1213  1335.1992 ]\n",
      " [2409.4749   760.7357  2483.0593   784.82043]\n",
      " [3390.2861   836.38904 3453.3347  1015.72705]\n",
      " [ 365.84445  314.21194  422.8798   333.62717]\n",
      " [3439.2388   777.1983  3473.0208   884.50696]\n",
      " [2183.4968  1810.606   2412.0706  2065.0852 ]\n",
      " [3372.0964   786.3285  3392.4302   850.75415]\n",
      " [2690.      1814.7228  2750.5176  1901.4861 ]\n",
      " [3438.5762   877.3353  3456.8074   942.7473 ]\n",
      " [3401.102    863.8792  3416.3147   912.48816]\n",
      " [1250.1177  1857.4233  1257.2233  1865.4614 ]\n",
      " [3313.91     767.03436 3372.4404   793.36536]]\n",
      "[0.99917066 0.9979693  0.99656975 0.9948953  0.9942054  0.9907505\n",
      " 0.9888976  0.98585296 0.9703456  0.96816874 0.96496546 0.9360676\n",
      " 0.9300508  0.88491106 0.8033866 ]\n"
     ]
    }
   ],
   "source": [
    "from inference_modular import ship_detection\n",
    "from PIL import Image\n",
    "# images_path = r\"D:\\NLP 1\\Sat_object_detection\\inference_images\"\n",
    "images_path = r\"D:\\NLP 1\\Sat_object_detection\\debug_images_2\\e7e24507a.jpg\"\n",
    "images_path = r\"D:\\NLP 1\\Sat_object_detection\\debug_images_2\\2.jpg\"\n",
    "img = Image.open(images_path)\n",
    "print(type(img))\n",
    "coord = {\"0c0d90d8d.jpg\": [58.4893887115,23.6396684794,58.4961460224,23.6487324542]}\n",
    "\n",
    "result = ship_detection(images=img, bbox_coord_wgs84=coord, annotations=[\"length\", \"coord\"], nms_iou_threshold=0.1,\n",
    "                        confidence_threshold=0.8, sahi_overlap_ratio=0.3, output_annotated_image=True, save_annotated_image=False, output_original_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['n_obj', 'bboxes', 'scores', 'original_image', 'ships_long_lat', 'ships_length', 'ships_bbox_dimensions', 'annotated_image'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"annotated_image\"]\n",
    "# result[\"original_image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use draw_bbox_torchvision separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageutils import draw_bbox_torchvision\n",
    "annotated_image = draw_bbox_torchvision(image=result[\"original_image\"], bboxes=result[\"bboxes\"], scores=result[\"scores\"], lengths=result[\"ships_length\"], \n",
    "                        ships_coords=result[\"ships_long_lat\"], annotations=[\"score\"], save=True, image_save_name=r\"C:\\Users\\user2\\Desktop\\b.jpg\", output_annotated_image=True)\n",
    "annotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image000', 'Image001', 'Image002', 'Image003', 'Image004', 'Image005', 'Image006', 'Image007', 'Image008', 'Image009', 'Image010', 'Image011', 'Image012', 'Image013', 'Image014', 'Image015', 'Image016', 'Image017', 'Image018', 'Image019', 'Image020', 'Image021', 'Image022', 'Image023', 'Image024', 'Image025', 'Image026', 'Image027', 'Image028', 'Image029', 'Image030', 'Image031', 'Image032', 'Image033', 'Image034', 'Image035', 'Image036', 'Image037', 'Image038', 'Image039', 'Image040', 'Image041', 'Image042', 'Image043', 'Image044', 'Image045', 'Image046', 'Image047', 'Image048', 'Image049', 'Image050', 'Image051', 'Image052', 'Image053', 'Image054', 'Image055', 'Image056', 'Image057', 'Image058', 'Image059', 'Image060', 'Image061', 'Image062', 'Image063', 'Image064', 'Image065', 'Image066', 'Image067', 'Image068', 'Image069', 'Image070', 'Image071', 'Image072', 'Image073', 'Image074', 'Image075', 'Image076', 'Image077', 'Image078', 'Image079', 'Image080', 'Image081', 'Image082', 'Image083', 'Image084', 'Image085', 'Image086', 'Image087', 'Image088', 'Image089', 'Image090', 'Image091', 'Image092', 'Image093', 'Image094', 'Image095', 'Image096', 'Image097', 'Image098', 'Image099']\n"
     ]
    }
   ],
   "source": [
    "images_names = [\"Image{0:03}\".format(i) for i in range(100)]\n",
    "images = [i for i in range(100)]\n",
    "\n",
    "images_dict = {images_names[i]:{\"image\": images[i]} for i in range(len(images_names))}\n",
    "images_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "def func(x, a, b, c):\n",
    "    return (a * x**2 + b*x + c) # a and d are redundant\n",
    "\n",
    "dim_c =  [2   , 3   ,  4   , 5   , 6  , 7   ,  8  ,  9  , 10 , ]\n",
    "dim_c2 = [1.2 , 1.4 , 1.6  , 1.8 , 2  , 2.2 , 2.4 , 2.6 ,  3 , ]\n",
    "p , _ = curve_fit(func, dim_c, dim_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0.01x**2 + 0.14*x + 0.92\n"
     ]
    }
   ],
   "source": [
    "print(f\"y = {p[0]:.2f}x**2 + {p[1]:.2f}*x + {p[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
