{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP 1\\venv\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "D:\\NLP 1\\venv\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from slicing_inference import sahi_slicing_inference\n",
    "from inference_modular import ship_detection_sahi\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from imageutils import resize_img\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\debug_images\\2.jpg\"\n",
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\inference_images\\dd4ffcb5c.jpg\"\n",
    "\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# model = torch.load('models/best_model.pth', map_location = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 1 number of slices.\n",
      "Object found -> bbox:  [ 73.13797  639.82117  124.770706 741.1826  ]\n",
      "Object found -> bbox:  [ 37.490547 137.97885   99.83393  229.94489 ]\n",
      "Object found -> bbox:  [579.8303  552.79254 610.90784 606.02045]\n"
     ]
    }
   ],
   "source": [
    "bbox_coord = [53.996172, 16.951560, 54.010077, 16.963793]\n",
    "result = ship_detection_sahi(image=image, bbox_coord_wgs84=bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'res_object': <sahi.prediction.PredictionResult at 0x22e7fd434d0>,\n",
       " 'n_obj': 3,\n",
       " 'bboxes': array([[ 73.13797 , 639.82117 , 124.770706, 741.1826  ],\n",
       "        [ 37.490547, 137.97885 ,  99.83393 , 229.94489 ],\n",
       "        [579.8303  , 552.79254 , 610.90784 , 606.02045 ]], dtype=float32),\n",
       " 'scores': array([0.99949455, 0.9990532 , 0.99712497], dtype=float32),\n",
       " 'sahi_scaled_down_image': <PIL.Image.Image image mode=RGB size=768x768>,\n",
       " 'ships_coord': [(53.997963614676, 16.962558580268),\n",
       "  (53.997415162024, 16.95449021554),\n",
       "  (54.006951436265, 16.960789009952)],\n",
       " 'ships_length': [205.2, 202.4, 111.7],\n",
       " 'ships_bbox_dimensions': [(179.5, 99.4), (162.9, 120.1), (94.3, 59.8)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path=r\"D:\\NLP 1\\Sat_object_detection\\inference_images\\dd4ffcb5c.jpg\"\n",
    "# image = Image.open(image_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAHI_SCALE_DOWN_FACTOR set to: 2\n",
      "Performing prediction on 35 number of slices.\n",
      "Object found -> bbox:  [365.84445 314.21194 422.8798  333.62717]\n",
      "Object found -> bbox:  [580.10266 404.423   665.64075 732.0508 ]\n",
      "Object found -> bbox:  [548.76794 232.16986 573.2628  310.2199 ]\n",
      "Object found -> bbox:  [564.43    146.43675 637.3945  170.1927 ]\n",
      "Object found -> bbox:  [2.5482941e-01 4.1782794e+02 4.3468842e+01 7.1294550e+02]\n",
      "Object found -> bbox:  [365.14713 162.96207 396.70053 268.37592]\n",
      "Object found -> bbox:  [316.6089  292.47156 342.76288 389.72583]\n",
      "Object found -> bbox:  [297.05743 173.99838 317.56848 234.91306]\n",
      "Object found -> bbox:  [363.67947 272.35434 382.48337 327.29276]\n",
      "Object found -> bbox:  [ 51.444565 161.20921   85.14     268.91467 ]\n",
      "Object found -> bbox:  [  3.8286781 292.93976    29.132156  389.64     ]\n",
      "Object found -> bbox:  [ 50.694202 274.86154   68.593956 326.1243  ]\n",
      "Object found -> bbox:  [559.8498  217.36679 618.7164  283.8817 ]\n",
      "Object found -> bbox:  [340.9956  588.1017  508.9184  764.06287]\n",
      "Object found -> bbox:  [144.0585  466.19012 195.90875 523.7467 ]\n",
      "Object found -> bbox:  [3.4738318e+02 7.0526123e-02 5.9599396e+02 2.1781741e+02]\n",
      "Object found -> bbox:  [8.9859009e-01 8.4381104e-03 2.7435013e+02 2.1220071e+02]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "any() takes exactly one argument (5 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32md:\\NLP 1\\Sat_object_detection\\debug.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP%201/Sat_object_detection/debug.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m bbox_coord \u001b[39m=\u001b[39m [\u001b[39m53.996172\u001b[39m, \u001b[39m16.951560\u001b[39m, \u001b[39m54.010077\u001b[39m, \u001b[39m16.963793\u001b[39m]\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLP%201/Sat_object_detection/debug.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m ship_detection_sahi(image\u001b[39m=\u001b[39;49mimage, bbox_coord_wgs84\u001b[39m=\u001b[39;49mbbox_coord)\n",
      "\n",
      "File \u001b[1;32md:\\NLP 1\\Sat_object_detection\\inference_modular.py:163\u001b[0m, in \u001b[0;36mship_detection_sahi\u001b[1;34m(image, model_path, bbox_coord_wgs84, model_input_dim, sahi_confidence_threshold, sahi_scale_down_factor, sahi_overlap_ratio, nms_iou_threshold, output_scaled_down_image, device)\u001b[0m\n",
      "\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m (lg1 \u001b[39m>\u001b[39m lg2) \u001b[39mor\u001b[39;00m (lt1 \u001b[39m>\u001b[39m lt2):\n",
      "\u001b[0;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\"\"\u001b[39m\u001b[39mbbox_coord_wgs84 is supposed to be in the following format:\u001b[39m\n",
      "\u001b[0;32m    158\u001b[0m \u001b[39m                                 [left, bottom, right, top]\u001b[39m\n",
      "\u001b[0;32m    159\u001b[0m \u001b[39m                                 or in other words: \u001b[39m\n",
      "\u001b[0;32m    160\u001b[0m \u001b[39m                                 [min Longitude , min Latitude , max Longitude , max Latitude]\u001b[39m\n",
      "\u001b[0;32m    161\u001b[0m \u001b[39m                                 or in other words: \u001b[39m\n",
      "\u001b[0;32m    162\u001b[0m \u001b[39m                                 [West Longitude , South Latitude , East Longitude , North Latitude]\u001b[39m\u001b[39m\"\"\"\u001b[39m)\n",
      "\u001b[1;32m--> 163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39;49m([(lg1 \u001b[39m>\u001b[39;49m \u001b[39m180\u001b[39;49m), (lg2 \u001b[39m>\u001b[39;49m \u001b[39m180\u001b[39;49m),\n",
      "\u001b[0;32m    164\u001b[0m         (lg1 \u001b[39m<\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m180\u001b[39;49m), (lg2 \u001b[39m<\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m180\u001b[39;49m)],\n",
      "\u001b[0;32m    165\u001b[0m         (lt1 \u001b[39m>\u001b[39;49m \u001b[39m90\u001b[39;49m), (lt2 \u001b[39m>\u001b[39;49m \u001b[39m90\u001b[39;49m),\n",
      "\u001b[0;32m    166\u001b[0m         (lt1 \u001b[39m<\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m90\u001b[39;49m), (lt2 \u001b[39m<\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m90\u001b[39;49m)):\n",
      "\u001b[0;32m    167\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\"\"\u001b[39m\u001b[39mWrong coordinations! Latitude is between -90 and 90 and\u001b[39m\n",
      "\u001b[0;32m    168\u001b[0m \u001b[39m                     Longitude is between -180 and 180. Also, the following format is required:\u001b[39m\n",
      "\u001b[0;32m    169\u001b[0m \u001b[39m                     [left, bottom, right, top]\u001b[39m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    173\u001b[0m \u001b[39m                     [West Longitude , South Latitude , East Longitude , North Latitude]\u001b[39m\n",
      "\u001b[0;32m    174\u001b[0m \u001b[39m                     \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n",
      "\u001b[0;32m    176\u001b[0m w_resized, h_resized \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mshape\n",
      "\n",
      "\u001b[1;31mTypeError\u001b[0m: any() takes exactly one argument (5 given)"
     ]
    }
   ],
   "source": [
    "bbox_coord = [53.996172, 16.951560, 54.010077, 16.963793]\n",
    "result = ship_detection_sahi(image=image, bbox_coord_wgs84=bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'res_object': <sahi.prediction.PredictionResult at 0x229b6148410>,\n",
       " 'n_obj': 3,\n",
       " 'bboxes': array([[ 73.13797 , 639.82117 , 124.770706, 741.1826  ],\n",
       "        [ 37.490547, 137.97885 ,  99.83393 , 229.94489 ],\n",
       "        [579.8303  , 552.79254 , 610.90784 , 606.02045 ]], dtype=float32),\n",
       " 'scores': array([0.99949455, 0.9990532 , 0.99712497], dtype=float32),\n",
       " 'sahi_scaled_down_image': Image([[[0.4039, 0.3765, 0.3373,  ..., 0.3647, 0.3451, 0.3255],\n",
       "         [0.3725, 0.3647, 0.3490,  ..., 0.3373, 0.3412, 0.3412],\n",
       "         [0.3725, 0.3686, 0.3608,  ..., 0.3922, 0.4078, 0.4157],\n",
       "         ...,\n",
       "         [0.4353, 0.4118, 0.3922,  ..., 0.3765, 0.3373, 0.3294],\n",
       "         [0.4353, 0.4235, 0.4039,  ..., 0.3333, 0.2980, 0.3059],\n",
       "         [0.4353, 0.4392, 0.4235,  ..., 0.3255, 0.3137, 0.3373]],\n",
       " \n",
       "        [[0.4431, 0.4157, 0.3765,  ..., 0.4039, 0.3843, 0.3647],\n",
       "         [0.4118, 0.4039, 0.3882,  ..., 0.3765, 0.3804, 0.3804],\n",
       "         [0.4118, 0.4078, 0.4000,  ..., 0.4314, 0.4471, 0.4549],\n",
       "         ...,\n",
       "         [0.4549, 0.4314, 0.4118,  ..., 0.4039, 0.3647, 0.3569],\n",
       "         [0.4549, 0.4431, 0.4235,  ..., 0.3608, 0.3255, 0.3333],\n",
       "         [0.4549, 0.4588, 0.4431,  ..., 0.3529, 0.3412, 0.3647]],\n",
       " \n",
       "        [[0.4118, 0.3843, 0.3451,  ..., 0.3686, 0.3490, 0.3294],\n",
       "         [0.3804, 0.3725, 0.3569,  ..., 0.3412, 0.3451, 0.3451],\n",
       "         [0.3804, 0.3765, 0.3686,  ..., 0.3961, 0.4118, 0.4196],\n",
       "         ...,\n",
       "         [0.4314, 0.4078, 0.3882,  ..., 0.3765, 0.3373, 0.3294],\n",
       "         [0.4314, 0.4196, 0.4000,  ..., 0.3333, 0.2980, 0.3059],\n",
       "         [0.4314, 0.4353, 0.4196,  ..., 0.3255, 0.3137, 0.3373]]], )}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 70 number of slices.\n",
      "Object found -> bbox:  [172.24466 219.75867 183.78247 252.8877 ]\n",
      "Object found -> bbox:  [178.79358 174.96414 215.41855 188.38754]\n",
      "Object found -> bbox:  [ 80.7796  184.60483  95.30228 237.50015]\n",
      "Object found -> bbox:  [ 56.39531 183.7208   66.48006 224.15482]\n",
      "Object found -> bbox:  [ 46.867878 190.34285   54.10033  219.8062  ]\n",
      "Object found -> bbox:  [ 87.29237  104.747406 126.65727  250.9613  ]\n",
      "Object found -> bbox:  [172.02037   14.113773 184.64522   49.890957]\n",
      "Object found -> bbox:  [56.044838 41.62107  67.34849  88.261986]\n",
      "Object found -> bbox:  [46.091427  0.       55.038563 15.20483 ]\n",
      "Object found -> bbox:  [81.16937     0.19804001 94.71823    30.920658  ]\n",
      "Object found -> bbox:  [80.39027 34.13742 88.7575  58.11094]\n",
      "Object found -> bbox:  [178.77655 109.04211 204.41302 139.4227 ]\n",
      "Object found -> bbox:  [ 72.8449   234.10031   93.480736 255.2612  ]\n",
      "Object found -> bbox:  [ 67.26007  87.34427 190.18393 215.46655]\n",
      "Object found -> bbox:  [73.17347  28.47319  96.60549  55.731316]\n",
      "Object found -> bbox:  [  5.4321938  96.69139   130.84628   209.5995   ]\n"
     ]
    }
   ],
   "source": [
    "image_path=r\"D:\\NLP 1\\Sat_object_detection\\debug_images\\2.jpg\"\n",
    "result = sahi_slicing_inference(image_path, scale_down_factor=4, confidence_threshold=0.85, model_input_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([[ 820.2710,  615.8837,  915.9689,  689.3981],\n",
      "        [ 605.2632,  342.0967,  630.9042,  443.5218],\n",
      "        [ 728.5158,  603.5172,  808.0978,  690.0929],\n",
      "        [1129.8649,  302.0988, 1137.3132,  332.0983],\n",
      "        [ 868.5435,  565.1304,  883.9681,  582.7642],\n",
      "        [ 802.4941,  253.8459,  826.7433,  261.3813],\n",
      "        [1145.9186,  257.6726, 1155.4994,  295.3320],\n",
      "        [ 836.2240,  222.5385, 1073.3400,  257.0076],\n",
      "        [ 797.9913,  283.8180,  806.2943,  304.2020]])\n",
      "tensor([0.9984, 0.9968, 0.9839, 0.9553, 0.9517, 0.9508, 0.9273, 0.9204, 0.8515])\n",
      "(1385, 918)\n"
     ]
    }
   ],
   "source": [
    "print(result['n_obj'])\n",
    "print(result['bboxes'])\n",
    "print(result['scores'])\n",
    "print(result[\"scaled_down_image_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['prediction'].export_visuals(export_dir=\"demo_data/\", hide_labels=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"res_object\"].export_visuals(r\"C:\\Users\\user2\\Desktop\\1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
